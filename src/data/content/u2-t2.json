{
    "id": "u2-t2",
    "title": "Query Operations (Relevance Feedback, Local/Global Analysis)",
    "unitId": "unit-2",
    "slides": [
        {
            "slideNumber": 1,
            "type": "title",
            "title": "Query Operations",
            "subtitle": "Iterative Query Refinement",
            "content": {
                "text": "The objective of query operations is to transform the user's initial query into a more effective search request through expansion or re-weighting.",
                "hook": "Search is not a one-step process; it's a conversation."
            }
        },
        {
            "slideNumber": 2,
            "type": "standard",
            "title": "Introduction to Query Operations",
            "content": {
                "text": "Users often provide short, ambiguous queries. Query operations help reduce this ambiguity by adding more terms (expansion) or changing term weights based on what the user likes (feedback)."
            }
        },
        {
            "slideNumber": 3,
            "type": "standard",
            "title": "User Relevance Feedback",
            "content": {
                "definition": "A cycle where the user marks results as Relevant or Non-Relevant, and the system uses this info to run a better query.",
                "text": "The classic approach is the Rocchio Algorithm which modifies query vectors based on user feedback.",
                "hook": "Teaching the system by example."
            },
            "formula": {
                "equation": "\\vec{q}_m = \\alpha \\vec{q}_0 + \\beta \\frac{1}{|D_r|} \\sum_{\\vec{d}_j \\in D_r} \\vec{d}_j - \\gamma \\frac{1}{|D_{nr}|} \\sum_{\\vec{d}_k \\in D_{nr}} \\vec{d}_k",
                "description": "Rocchio Algorithm modifies the original query vector by moving it toward relevant documents and away from non-relevant ones.",
                "terms": [
                    {
                        "symbol": "\\vec{q}_m",
                        "meaning": "Modified (new) query vector after relevance feedback"
                    },
                    {
                        "symbol": "\\vec{q}_0",
                        "meaning": "Original query vector before feedback"
                    },
                    {
                        "symbol": "\\alpha",
                        "meaning": "Weight for original query (typical: 1.0) - controls trust in initial query"
                    },
                    {
                        "symbol": "\\beta",
                        "meaning": "Weight for relevant documents (typical: 0.75) - how much to move toward relevant docs"
                    },
                    {
                        "symbol": "\\gamma",
                        "meaning": "Weight for non-relevant documents (typical: 0.15) - how much to move away from irrelevant docs"
                    },
                    {
                        "symbol": "D_r",
                        "meaning": "Set of documents marked as relevant by the user"
                    },
                    {
                        "symbol": "|D_r|",
                        "meaning": "Number of relevant documents"
                    },
                    {
                        "symbol": "D_{nr}",
                        "meaning": "Set of documents marked as non-relevant"
                    },
                    {
                        "symbol": "\\vec{d}_j",
                        "meaning": "Document vector for the j-th relevant document"
                    },
                    {
                        "symbol": "\\sum \\vec{d}_j / |D_r|",
                        "meaning": "Centroid (average vector) of relevant documents"
                    }
                ]
            }
        },
        {
            "slideNumber": 4,
            "type": "standard",
            "title": "Automatic Local Analysis",
            "content": {
                "text": "Also known as Indirect Feedback or Pseudo-Relevance Feedback. The system 'assumes' the top K retrieved documents are relevant without asking the user.",
                "outcomes": [
                    "Identifies common terms in the top results.",
                    "Expands the query with those terms.",
                    "Fast and automated, but risky if the first results are bad."
                ]
            }
        },
        {
            "slideNumber": 5,
            "type": "standard",
            "title": "Automatic Global Analysis",
            "content": {
                "text": "Expansion based on the entire document collection, not just the local results of a single query.",
                "outcomes": [
                    "Thesaurus-based expansion: Using WordNet or a statistical thesaurus.",
                    "Latent Semantic Indexing: Finding hidden relationships between words globally.",
                    "Computationally expensive but more stable than local analysis."
                ]
            }
        },
        {
            "slideNumber": 6,
            "type": "grid",
            "title": "Comparison: Local vs Global",
            "items": [
                "Local: Quick, context-specific, can cause 'Query Drift'.",
                "Global: Robust, costly to compute, handles synonyms well."
            ]
        },
        {
            "slideNumber": 7,
            "type": "activity",
            "title": "Activity: Manual Expansion",
            "content": {
                "activity": "The Brainstorm",
                "description": "Original Query: 'Smart Watch'. List 5 terms using Local Analysis (words common in watch ads) and 5 terms using Global Analysis (synonyms from a dictionary)."
            }
        },
        {
            "slideNumber": 8,
            "type": "quiz",
            "title": "Concept Quiz",
            "questions": [
                "What is the main goal of the Rocchio algorithm?",
                "Explain how Pseudo-Relevance feedback works.",
                "When would you use Global Analysis instead of Local Analysis?",
                "What is 'Query Drift'?"
            ]
        },
        {
            "slideNumber": 9,
            "type": "summary",
            "title": "Trends and Research Issues",
            "content": {
                "text": "Modern trends include Neural Query Expansion (using embeddings) and Intent Mining from user click-logs.",
                "nextTopic": "Text Operations",
                "preparation": "Learn about Stemming and Lemmatization."
            }
        }
    ]
}