{
    "id": "u4-t6",
    "title": "Question Answering",
    "unitId": "unit-4",
    "slides": [
        {
            "slideNumber": 1,
            "type": "title",
            "title": "Question Answering Systems",
            "subtitle": "Beyond Document Lists",
            "content": {
                "text": "Users often don't want a list of documents; they want an answer. QA systems extract specific facts or generate responses from a corpus.",
                "hook": "Search: 'Where is Tokyo?' -> [Link 1, Link 2]. QA: 'Where is Tokyo?' -> 'Tokyo is in Japan.'"
            }
        },
        {
            "slideNumber": 2,
            "type": "grid",
            "title": "Types of Questions",
            "items": [
                "Factoid: 'Who is the president?' (Named Entity).",
                "List: 'List the countries in Africa.'",
                "Definition: 'What is a search engine?'",
                "Opinion/Why: 'Why is AI dangerous?' (Complex synthesis)."
            ]
        },
        {
            "slideNumber": 3,
            "type": "standard",
            "title": "QA Architecture",
            "content": {
                "text": "The traditional pipeline for QA.",
                "steps": [
                    "Question Processing: Determine 'Answer Type' (Person, Date, etc).",
                    "Document Retrieval: Find relevant passages.",
                    "Answer Extraction: Pinpoint the exact string in the text.",
                    "Ranking: Choose the most confident answer."
                ]
            },
            "formula": {
                "equation": "\\text{MRR} = \\frac{1}{|Q|} \\sum_{i=1}^{|Q|} \\frac{1}{rank_i}",
                "description": "Mean Reciprocal Rank (MRR) is the standard metric for evaluating QA systems, where we care only about the position (rank) of the first correct answer.",
                "terms": [
                    {
                        "symbol": "Q",
                        "meaning": "The set of sample questions"
                    },
                    {
                        "symbol": "rank_i",
                        "meaning": "The position of the first correct answer for question 'i'"
                    },
                    {
                        "symbol": "1/rank",
                        "meaning": "Reciprocal rank (1st place = 1.0, 2nd = 0.5, 3rd = 0.33)"
                    }
                ],
                "calculation": {
                    "exampleTitle": "QA System Benchmark",
                    "description": "Evaluating 3 queries against a QA system.",
                    "steps": [
                        {
                            "label": "Query 1",
                            "formula": "rank_1 = 1",
                            "note": "Correct answer found at top spot (Score: 1.0)."
                        },
                        {
                            "label": "Query 2",
                            "formula": "rank_2 = 2",
                            "note": "Correct answer was the second suggestion (Score: 0.5)."
                        },
                        {
                            "label": "Query 3",
                            "formula": "rank_3 = 10",
                            "note": "Answer found deep in the list (Score: 0.1)."
                        },
                        {
                            "label": "Calculate MRR",
                            "formula": "MRR = (1 + 0.5 + 0.1) / 3 = 0.533",
                            "note": "Final system score is 0.533."
                        }
                    ],
                    "input": "Ranks:[1, 2, 10]",
                    "output": "MRR: 0.53"
                }
            }
        },
        {
            "slideNumber": 4,
            "type": "standard",
            "title": "The Role of NLP",
            "content": {
                "text": "QA relies heavily on Natural Language Processing (NLP) techniques like Named Entity Recognition (NER), Part-of-Speech tagging, and Semantic Parsing.",
                "hook": "Modern QA systems (like LLMs) generate answers by predicting next tokens, but traditional systems 'highlight' existing facts."
            }
        },
        {
            "slideNumber": 5,
            "type": "activity",
            "title": "Activity: Extract the Fact",
            "content": {
                "activity": "The QA Challenge",
                "description": "Text: 'Dr. Muzamil founded the IR lab in 2024.' Question: 'Who founded the lab?' What part of speech is the answer? What entity type?"
            }
        },
        {
            "slideNumber": 6,
            "type": "python_demo",
            "title": "Python Demo: Question Answering Logic",
            "content": {
                "code": "def answer_question(query, candidates):\n    # Simple keyword overlap for QA\n    q_words = set(query.lower().split())\n    scores = []\n    for c in candidates:\n        overlap = len(q_words & set(c.lower().split()))\n        scores.append((overlap, c))\n    return sorted(scores, reverse=True)[0][1]\n\nquestion = \"Who founded Google?\"\nkb = [\"Google was founded by Larry Page.\", \"IR is a field.\"]\nprint(f\"Answer: {answer_question(question, kb)}\")",
                "input": "Q: 'Who founded Google?', KB: [..., ...]",
                "output": "Answer: Google was founded by Larry Page.",
                "interpretation": "QA systems try to find the specific fact, not just documents.\nBy matching question words against a knowledge base, it extracts the most likely candidate.\nThis is the technology behind Alexa and Siri."
            }
        },
        {
            "slideNumber": 7,
            "type": "summary",
            "title": "Course Wrap-up",
            "content": {
                "linkage": "You have completed the full course on B22EQ0601 Information Retrieval. From basic models to advanced recommendation and QA systems.",
                "nextTopic": "Final Assessment",
                "preparation": "Review all units for the final course project."
            }
        }
    ]
}