{
    "id": "u3-t2",
    "title": "The Information Access Process",
    "unitId": "unit-3",
    "slides": [
        {
            "slideNumber": 1,
            "type": "title",
            "title": "The Information Access Process",
            "subtitle": "Iterative Learning and Discovery",
            "content": {
                "text": "Accessing information is rarely a single event. It is a process of learning, where each result informs the next query.",
                "hook": "Search is a journey, not a destination."
            }
        },
        {
            "slideNumber": 2,
            "type": "standard",
            "title": "The Classic vs Dynamic Model",
            "content": {
                "text": "Standard Model: User need -> Query -> Results -> Satisfaction.\nDynamic Model (Berry-Picking): User need evolves. Each document reveals new concepts, leading to new queries. The final 'answer' is a synthesis of many clicks.",
                "outcomes": [
                    "Need for persistent search history",
                    "Importance of 'pivoting' on new keywords"
                ]
            },
            "formula": {
                "equation": "U_{total} = \\sum_{i=1}^{n} Gain(d_i) \\cdot P(r_i)",
                "description": "The total utility of an information access process is the sum of relevant information (Gain) extracted from each document 'd' encountered on the search path.",
                "terms": [
                    {
                        "symbol": "U_{total}",
                        "meaning": "Cumulative utility/knowledge gained by the user"
                    },
                    {
                        "symbol": "Gain(d_i)",
                        "meaning": "New, non-redundant information found in document i"
                    },
                    {
                        "symbol": "P(r_i)",
                        "meaning": "Probability that the user actually reads/reaches document i"
                    }
                ],
                "calculation": {
                    "exampleTitle": "Berry-Picking Utility",
                    "description": "Calculating total knowledge gain from 3 partially relevant docs.",
                    "steps": [
                        {
                            "label": "Document 1",
                            "formula": "Gain=10, P=1.0",
                            "note": "First doc seen, all info is new."
                        },
                        {
                            "label": "Document 2",
                            "formula": "Gain=5, P=0.8",
                            "note": "Some info overlaps with Doc 1; 80% chance of reading."
                        },
                        {
                            "label": "Document 3",
                            "formula": "Gain=2, P=0.5",
                            "note": "Mostly redundant; 50% chance user stopped before here."
                        },
                        {
                            "label": "Total Utility",
                            "formula": "U = (10 \\times 1) + (5 \\times 0.8) + (2 \\times 0.5) = 15",
                            "note": "Synthesis of information across multiple encounters."
                        }
                    ],
                    "input": "Gains:[10, 5, 2], Probs:[1.0, 0.8, 0.5]",
                    "output": "Total Info Value: 15"
                }
            }
        },
        {
            "slideNumber": 3,
            "type": "diagram",
            "title": "Integrated Search Cycle",
            "content": {
                "description": "Steps in the access process.",
                "steps": [
                    "Recognizing Need",
                    "Selecting Source",
                    "Formulating Query",
                    "Inspecting Results",
                    "Extracting Information",
                    "Reformulating"
                ]
            }
        },
        {
            "slideNumber": 4,
            "type": "standard",
            "title": "Cognitive Models",
            "content": {
                "text": "Explores how users think during search. 1. Anomalous State of Knowledge (ASK): Searchers have a gap in knowledge and don't know the words to fill it yet. 2. Sensemaking: Building a mental map of a topic through multiple searches."
            }
        },
        {
            "slideNumber": 5,
            "type": "activity",
            "title": "Activity: Trace Your Clicks",
            "content": {
                "activity": "The Paper Trail",
                "description": "Research 'Why do cats purr?'. List every search term you used from start to final answer. Did your first query give you the answer, or did it just give you the vocabulary for the second?"
            }
        },
        {
            "slideNumber": 6,
            "type": "quiz",
            "title": "Topic Quiz",
            "questions": [
                "What is the Berry-Picking model?",
                "Explain the 'Anomalous State of Knowledge' (ASK).",
                "How does the dynamic model differ from the boolean model of access?",
                "Define 'Sensemaking'."
            ]
        },
        {
            "slideNumber": 7,
            "type": "python_demo",
            "title": "Python Demo: K-Means Clustering",
            "content": {
                "code": "import random\n\ndef mock_cluster(docs, k=2):\n    # Simplified: Random assignment for demo\n    clusters = {i: [] for i in range(k)}\n    for d in docs:\n        clusters[random.randint(0, k-1)].append(d)\n    return clusters\n\ndoc_list = [\"Python basics\", \"Java guide\", \"Snake care\", \"C++ manual\"]\nprint(f\"Clusters: {mock_cluster(doc_list)}\")",
                "input": "['Python basics', 'Java guide', 'Snake care', 'C++ manual']",
                "output": "Clusters: {0: ['Python basics', 'C++ manual'], 1: ['Java guide', 'Snake care']}",
                "interpretation": "Clustering groups results into folders (e.g., Programming vs Biology).\nEven with simple logic, it helps organize overwhelming result sets.\nModern IR uses K-Means or Hierarchical clustering for 'Result-Set Organization'."
            }
        },
        {
            "slideNumber": 8,
            "type": "summary",
            "title": "Wrap-up",
            "content": {
                "text": "Process defined. Next: Where does it all begin on the screen?",
                "nextTopic": "Starting Points & Query Specification",
                "preparation": "Look at the homepage of Google vs. a news site."
            }
        }
    ]
}