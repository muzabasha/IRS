{
    "id": "u1-t2",
    "title": "The Retrieval Process",
    "unitId": "unit-1",
    "slides": [
        {
            "slideNumber": 1,
            "type": "title",
            "title": "The Information Retrieval Process",
            "subtitle": "From User Need to Ranked Results",
            "content": {
                "text": "Understanding the complete lifecycle of a search query: how a user's vague information need is transformed, matched, and satisfied by an IR system.",
                "hook": "A search engine is a conversation between a user and a collection of documents."
            }
        },
        {
            "slideNumber": 2,
            "type": "standard",
            "title": "The User Task",
            "content": {
                "text": "The process begins with a user's 'Information Need'. This is distinct from the 'Query' they type. The gap between the two is often where retrieval fails.",
                "definition": "Information Need: A desire to locate and obtain information to satisfy a conscious or unconscious need."
            }
        },
        {
            "slideNumber": 3,
            "type": "grid",
            "title": "Types of IR Tasks",
            "items": [
                "Ad-hoc Retrieval: Standard search (e.g., Google). One-time query on a static collection.",
                "Filtering/Routing: Static query on a dynamic stream (e.g., News alerts).",
                "Browsing: User navigates a structure (e.g., Directory) with no specific query.",
                "Question Answering: Returning a specific fact rather than a document list."
            ]
        },
        {
            "slideNumber": 4,
            "type": "diagram",
            "title": "The Retrieval Cycle",
            "content": {
                "description": "The formalized process of retrieval.",
                "steps": [
                    "User Input",
                    "Query Parsing",
                    "Logical View (Keywords)",
                    "Index Lookup",
                    "Ranking",
                    "Result Presentation"
                ]
            }
        },
        {
            "slideNumber": 5,
            "type": "standard",
            "title": "Logical View of Documents",
            "content": {
                "text": "Computers don't understand meaning; they understand patterns. We transform full text into a 'Logical View'â€”usually a set of index terms (keywords).",
                "outcomes": [
                    "Full Text: 'The quick brown fox jumps...'",
                    "Logical View: {fox, brown, quick, jump}"
                ]
            }
        },
        {
            "slideNumber": 6,
            "type": "list",
            "title": "Text Operations (Preprocessing)",
            "items": [
                "Lexical Analysis: Treating digits, hyphens, punctuation.",
                "Stopword Elimination: Removing 'the', 'of', 'and'.",
                "Stemming: Reducing 'computing', 'computed' to 'comput'.",
                "Thesaurus Expansion: Adding synonyms (e.g., car -> automobile)."
            ]
        },
        {
            "slideNumber": 7,
            "type": "illustration",
            "title": "Inverted Index Structure",
            "content": {
                "description": "Logic of the Inverted Index data structure.",
                "steps": [
                    "Vocabulary (Terms)",
                    "Postings Lists (DocIDs)",
                    "Frequency/Positions",
                    "Pointer Linkage"
                ]
            }
        },
        {
            "slideNumber": 8,
            "type": "activity",
            "title": "Activity: Query Translation",
            "content": {
                "activity": "The Telephone Game",
                "description": "Think of a complex question you have (e.g., 'Why is the sky blue?'). Now write down 3 different keyword queries you would type into Google to find the answer. Notice how you simplified the language."
            }
        },
        {
            "slideNumber": 9,
            "type": "standard",
            "title": "Matching & Ranking",
            "content": {
                "text": "The core intelligence of the system. It calculates a score for each document (Sim(q, d)) indicating how well it matches the query.",
                "hook": "Ranking is what separates a search engine from a database."
            },
            "formula": {
                "equation": "J(A, B) = \\frac{|A \\cap B|}{|A \\cup B|} = \\frac{|A \\cap B|}{|A| + |B| - |A \\cap B|}",
                "description": "The Jaccard Coefficient is a simple set-theoretic measure of similarity between a query and a document.",
                "terms": [
                    {
                        "symbol": "J(A, B)",
                        "meaning": "Jaccard similarity score (range: 0 to 1)"
                    },
                    {
                        "symbol": "A",
                        "meaning": "The set of unique terms in Document A"
                    },
                    {
                        "symbol": "B",
                        "meaning": "The set of unique terms in Query B"
                    },
                    {
                        "symbol": "|A \\cap B|",
                        "meaning": "Number of terms present in both the document and the query"
                    },
                    {
                        "symbol": "|A \\cup B|",
                        "meaning": "Total number of unique terms in the combination of document and query"
                    }
                ],
                "calculation": {
                    "exampleTitle": "Set-Theoretic Matching",
                    "description": "Comparing a query 'blue sky' with a document.",
                    "steps": [
                        {
                            "label": "Tokenize Input",
                            "formula": "Q = \\{blue, sky\\}, D = \\{sky, clear, sunny\\}",
                            "note": "Document mentions sky but not blue."
                        },
                        {
                            "label": "Calculate Intersection",
                            "formula": "|Q \\cap D| = |\\{sky\\}| = 1",
                            "note": "They share 1 word."
                        },
                        {
                            "label": "Calculate Union",
                            "formula": "|Q \\cup D| = |\\{blue, sky, clear, sunny\\}| = 4",
                            "note": "There are 4 unique words total."
                        },
                        {
                            "label": "Jaccard Score",
                            "formula": "J = \\frac{1}{4} = 0.25",
                            "note": "Similarity is 25%."
                        }
                    ],
                    "input": "Q:2 terms, D:3 terms, Overlap:1",
                    "output": "Sim: 0.25"
                }
            }
        },
        {
            "slideNumber": 10,
            "type": "project",
            "title": "Mini-Project: Tokenizer",
            "content": {
                "idea": "Build a Text Normalizer",
                "input": "A string: 'Hello, World! This is IR 101.'",
                "process": "1. Lowercase. 2. Remove Punctuation. 3. Split by space.",
                "output": "['hello', 'world', 'this', 'is', 'ir', '101']"
            }
        },
        {
            "slideNumber": 11,
            "type": "quiz",
            "title": "Check Your Understanding",
            "questions": [
                "What is the difference between Ad-hoc retrieval and Filtering?",
                "Why do we reduce documents to a 'Logical View'?",
                "If a user wants 'apple' (the fruit) but types 'apple' (the brand), what kind of problem is this?",
                "Name one advantage of stemming."
            ],
            "answers": [
                "Ad-hoc is a one-time query on a static collection, while Filtering is a static query (profile) on a dynamic document stream.",
                "Computers cannot understand full text meaning efficiently; a 'Logical View' (keywords) allows for efficient indexing and matching.",
                "This is a Polysemy (Ambiguity) problem.",
                "It improves recall by matching variations of a word (e.g., 'fish', 'fishing', 'fished') to the same root query term."
            ]
        },
        {
            "slideNumber": 12,
            "type": "python_demo",
            "title": "Python Demo: Text Tokenization Pipeline",
            "content": {
                "code": "import re\n\ndef simple_tokenizer(text):\n    # 1. Lowercase\n    text = text.lower()\n    # 2. Remove punctuation using regex\n    text = re.sub(r'[^a-z0-9\\s]', '', text)\n    # 3. Split by whitespace\n    tokens = text.split()\n    return tokens\n\nraw_data = \"Hello, IR Student! Welcome to Unit 1: Introduction to IR.\"\nclean_tokens = simple_tokenizer(raw_data)\nprint(f\"Raw: {raw_data}\")\nprint(f\"Tokens: {clean_tokens}\")",
                "input": "\"Hello, IR Student! Welcome to Unit 1: Introduction to IR.\"",
                "output": "Raw: Hello, IR Student! Welcome to Unit 1: Introduction to IR.\nTokens: ['hello', 'ir', 'student', 'welcome', 'to', 'unit', '1', 'introduction', 'to', 'ir']",
                "interpretation": "Tokenization is the first step in the retrieval process. \nBy converting text to lowercase and removing punctuation, we ensure that 'Hello,' and 'hello' are treated as the same index term.\nThis normalization is crucial for increasing the probability of a match between a query and a document."
            }
        },
        {
            "slideNumber": 13,
            "type": "research_perspective",
            "title": "Research Perspective: The User-System Interaction Model",
            "content": {
                "researchQuestions": [
                    {
                        "question": "Cognitive Load vs. System Recall: Is there a mathematical upper bound to how many results a human can process before precision becomes irrelevant?",
                        "answer": "Academic research in Interactive IR (IIR) utilizes 'Information Foraging Theory' to model users as optimal foragers. Mathematically, there is a 'diminishing returns' point where the cost of scanning (cognitive load) exceeds the expected gain in information. Advanced systems use this to dynamically truncate result lists or switch from ranking to summarization when confidence drops below a threshold."
                    },
                    {
                        "question": "The Vocabulary Mismatch Problem: To what extent can automated query expansion solve semantic ambiguity without introducing 'Query Drift'?",
                        "answer": "Query Drift occurs when expansion terms (synonyms) shift the query's meaning away from the original intent (e.g., expanding 'jaguar' to 'car' when the user wanted 'animal'). Research uses 'Pseudo-Relevance Feedback' models to measure the variance in term co-occurrence matrices, only expanding when the top-k results show high internal coherence."
                    }
                ],
                "mathematicalModeling": {
                    "problemStatement": "Modeling the Information Retrieval Process as a Markov Decision Process (MDP).",
                    "derivation": [
                        {
                            "step": "Define the state S as the user's current knowledge state and the query representation.",
                            "equation": "S_t = \\{Q_t, R_{1:t}, D_{1:t}\\}",
                            "interpretation": "The state includes the current query, previous rewards (relevance), and viewed documents."
                        },
                        {
                            "step": "Model the user's action A (reformulating or clicking) as a transition between states.",
                            "equation": "P(S_{t+1} | S_t, A_t)",
                            "interpretation": "Each search action changes the system's state and the user's understanding."
                        },
                        {
                            "step": "Define the Value Function for an optimal search policy.",
                            "equation": "V(s) = \\max_a \\sum_{s'} P(s'|s,a) [R(s,a,s') + \\gamma V(s')]",
                            "interpretation": "The Bellman equation shows that a user chooses search actions to maximize the total 'Expected Information Gain'."
                        }
                    ],
                    "conclusion": "Information Retrieval is not just a static match but a dynamic optimization problem where the 'Optimal Searcher' balances the exploration of new terms and exploitation of current high-ranking documents."
                }
            }
        },
        {
            "slideNumber": 14,
            "type": "summary",
            "title": "Topic Wrap-up",
            "content": {
                "linkage": "We've defined the process. Next, we need mathematical models to perform the 'Ranking' step.",
                "nextTopic": "Classic IR Models",
                "preparation": "Refresh your knowledge of Sets (Union, Intersection) and Vectors (Dot Product)."
            }
        }
    ]
}