{
    "id": "u3-t6",
    "title": "Trends and Research Issues (UI)",
    "unitId": "unit-3",
    "slides": [
        {
            "slideNumber": 1,
            "type": "title",
            "title": "Trends & Research in IR Interfaces",
            "subtitle": "The Future of Information Interaction",
            "content": {
                "text": "The way we interact with information is moving beyond static lists and keyboards. This topic explores the cutting-edge research in UI/UX for IR.",
                "hook": "We are moving from 'searching' to 'conversing'."
            }
        },
        {
            "slideNumber": 2,
            "type": "standard",
            "title": "Conversational Search",
            "content": {
                "text": "The rise of Large Language Models (LLMs) and Voice assistants. Instead of queries, users engage in dialogue. The system must maintain state and understand intent through multi-turn interactions.",
                "hook": "Siri, Alexa, and Gemini are the new 'browsers'."
            }
        },
        {
            "slideNumber": 3,
            "type": "grid",
            "title": "Modern Research Directions",
            "items": [
                "Neuro-symbolic interfaces (combining LLMs with structured data).",
                "Augmented Reality (AR) search interfaces.",
                "Collaborative Search (multiple people searching together).",
                "Affective IR (sensing user emotion through behavior)."
            ]
        },
        {
            "slideNumber": 4,
            "type": "standard",
            "title": "Human-Centered Evaluation",
            "content": {
                "text": "How do we measure 'Ease of use' or 'Joy' in IR? Research into biometric feedback (eye-tracking), EEG, and long-term user logs to understand satisfaction beyond just relevance.",
                "outcomes": [
                    "User experience (UX) as a ranking signal.",
                    "Personalization vs Privacy trade-off."
                ]
            },
            "formula": {
                "equation": "RT = a + b \\log_2(n)",
                "description": "Hick's Law calculates the reaction time (RT) for a user to make a decision based on the number of choices (n). In IR interfaces, this directs us to keep menus and facet lists concise to minimize cognitive load.",
                "terms": [
                    {
                        "symbol": "RT",
                        "meaning": "Reaction time required to make a selection"
                    },
                    {
                        "symbol": "n",
                        "meaning": "Number of equally probable choices (e.g., number of links in a menu)"
                    },
                    {
                        "symbol": "a, b",
                        "meaning": "Constants representing baseline time and processing rate"
                    }
                ],
                "calculation": {
                    "exampleTitle": "Menu Optimization",
                    "description": "Comparing choice time for a long list vs a grouped list.",
                    "steps": [
                        {
                            "label": "Original List",
                            "formula": "n = 16 \\text{ items}",
                            "note": "A single long list of categories."
                        },
                        {
                            "label": "Grouped List",
                            "formula": "n = 4 \\text{ items}",
                            "note": "4 main categories, each with 4 sub-items."
                        },
                        {
                            "label": "Time Complexity (16)",
                            "formula": "\\log_2(16) = 4 \\text{ units}",
                            "note": "Double the choices doesn't mean double the time (logarithmic)."
                        },
                        {
                            "label": "Time Complexity (4)",
                            "formula": "\\log_2(4) = 2 \\text{ units}",
                            "note": "Fewer choices significantly speed up initial target acquisition."
                        }
                    ],
                    "input": "n1:16, n2:4",
                    "output": "50% reduction in choice complexity"
                }
            }
        },
        {
            "slideNumber": 5,
            "type": "activity",
            "title": "Activity: Predict the 2030s",
            "content": {
                "activity": "The Inventor",
                "description": "Imagine search 10 years from now. Will screens still be the primary interface? Describe a search scenario using AR glasses or brain-computer interfaces."
            }
        },
        {
            "slideNumber": 6,
            "type": "quiz",
            "title": "Topic Quiz",
            "questions": [
                "What is 'Conversational Search'?",
                "How does Eye-tracking help in IR research?",
                "Name one trend in mobile search interface.",
                "What is 'Collaborative Search'?"
            ]
        },
        {
            "slideNumber": 7,
            "type": "summary",
            "title": "Unit Wrap-up",
            "content": {
                "text": "Unit 3 complete. We have mastered the human-machine interface. Next, we move into the complex world of Multimedia Retrieval.",
                "nextTopic": "Unit 4: Multimedia IR",
                "preparation": "Recall image search experiences on Google or Pinterest."
            }
        }
    ]
}