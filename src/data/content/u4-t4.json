{
    "id": "u4-t4",
    "title": "Search Engines, Browsing & Meta Searchers",
    "unitId": "unit-4",
    "slides": [
        {
            "slideNumber": 1,
            "type": "title",
            "title": "Navigating the Web",
            "subtitle": "Spiders, Browsers, and Meta-Search",
            "content": {
                "text": "How do we find what we need among trillions of documents? We use a combination of directed search (Engines), exploration (Browsing), and aggregation (Meta Searchers).",
                "hook": "Finding a needle in a haystack becomes easy if you have a thousand people looking for you."
            }
        },
        {
            "slideNumber": 2,
            "type": "standard",
            "title": "Search Engine Architecture",
            "content": {
                "text": "1. Crawler (Spider): Traversing links and downloading pages. 2. Indexer: Building the massive Inverted Index. 3. Query Processor: Ranking results in milliseconds.",
                "hook": "Engine = Crawling + Indexing + Ranking."
            }
        },
        {
            "slideNumber": 3,
            "type": "standard",
            "title": "Meta Searchers",
            "content": {
                "definition": "A search tool that sends your query to multiple other search engines and aggregates their results.",
                "text": "Meta searchers provide: 1. Broader coverage, 2. Combined ranking, 3. No local index of their own (they are 'leeches' of the search web).",
                "examples": [
                    "Dogpile",
                    "MetaCrawler"
                ]
            },
            "formula": {
                "equation": "S_{total}(d) = \\sum_{e \\in E} w_e \\cdot Score(d, e)",
                "description": "Meta-search engines aggregate rankings using consensus methods like the Borda Count or weighted summation of scores from multiple underlying engines.",
                "terms": [
                    {
                        "symbol": "S_{total}(d)",
                        "meaning": "Final aggregate score for document 'd'"
                    },
                    {
                        "symbol": "e",
                        "meaning": "One of the component search engines (e.g., Google, Bing)"
                    },
                    {
                        "symbol": "w_e",
                        "meaning": "Weight (trust) assigned to engine 'e'"
                    },
                    {
                        "symbol": "Score(d, e)",
                        "meaning": "Normalized score assigned to document 'd' by engine 'e'"
                    }
                ],
                "calculation": {
                    "exampleTitle": "Aggregation Case Study",
                    "description": "Merging results for a document from 2 engines with different weights.",
                    "steps": [
                        {
                            "label": "Engine Scores",
                            "formula": "Score_{G} = 0.9, Score_{B} = 0.4",
                            "note": "Document ranked high in Google, moderate in Bing."
                        },
                        {
                            "label": "Define weights",
                            "formula": "w_{G} = 0.7, w_{B} = 0.3",
                            "note": "We trust Google's ranking more."
                        },
                        {
                            "label": "Calculate Aggregate",
                            "formula": "S = (0.7 \\times 0.9) + (0.3 \\times 0.4)",
                            "note": "Weighted average calculation."
                        },
                        {
                            "label": "Final Score",
                            "formula": "S = 0.63 + 0.12 = 0.75",
                            "note": "Combined score represents a consensus of sources."
                        }
                    ],
                    "input": "Scores:[0.9, 0.4], Weights:[0.7, 0.3]",
                    "output": "Meta-Score: 0.75"
                }
            }
        },
        {
            "slideNumber": 4,
            "type": "standard",
            "title": "Finding the Needle in the Haystack",
            "content": {
                "text": "This refers to Search Effectiveness (Precision/Recall) on a web scale. 1. High Precision is critical (users only look at page 1). 2. Diversification: Ensuring the top results are diverse (e.g. searching 'Apple' shows the fruit AND the company).",
                "outcomes": [
                    "Ranking by Authority",
                    "User click-through signals"
                ]
            }
        },
        {
            "slideNumber": 5,
            "type": "activity",
            "title": "Activity: Meta-Search Test",
            "content": {
                "activity": "The Aggregator",
                "description": "Go to Dogpile.com. Search for 'Quantum Computing'. Compare the results at the top with a standard Google search. Are the 'Meta' results more diverse or just noisier?"
            }
        },
        {
            "slideNumber": 6,
            "type": "quiz",
            "title": "Topic Quiz",
            "questions": [
                "What is a 'Meta Searcher'?",
                "List the three main components of a Search Engine.",
                "Why is 'Precision' more important than 'Recall' for web search users?",
                "What does 'Finding the Needle' refer to in IR?"
            ]
        },
        {
            "slideNumber": 7,
            "type": "python_demo",
            "title": "Python Demo: Simple PageRank",
            "content": {
                "code": "def pagerank_iteration(ranks, adj_matrix, d=0.85):\n    N = len(ranks)\n    new_ranks = [(1-d)/N] * N\n    for i in range(N):\n        for j in range(N):\n            if adj_matrix[j][i]: # If j links to i\n                new_ranks[i] += d * (ranks[j] / sum(adj_matrix[j]))\n    return [round(r, 3) for r in new_ranks]\n\n# Node 0 links to 1, Node 1 links to 0\nr = [0.5, 0.5]\nm = [[0, 1], [1, 0]]\nprint(f\"Next Rank: {pagerank_iteration(r, m)}\")",
                "input": "Ranks: [0.5, 0.5], Matrix: bidirectional",
                "output": "Next Rank: [0.5, 0.5]",
                "interpretation": "PageRank simulates a 'Random Surfer' on the web graph.\nA page's score depends on the number and quality of incoming links.\nLinks from authoritative sites carry more weight than links from unknown ones."
            }
        },
        {
            "slideNumber": 8,
            "type": "summary",
            "title": "Wrap-up",
            "content": {
                "text": "Tools mastered. Finally, we look at the 'secret sauce' of web ranking.",
                "nextTopic": "Searching using Hyperlinks",
                "preparation": "Visualize a network of friends recommending each other."
            }
        }
    ]
}