{
    "id": "u2-t4",
    "title": "Indexing and Searching (Inverted Files, Boolean, Pattern)",
    "unitId": "unit-2",
    "slides": [
        {
            "slideNumber": 1,
            "type": "title",
            "title": "Indexing and Searching",
            "subtitle": "The Mechanics of Rapid Retrieval",
            "content": {
                "text": "How do we search billions of pages in milliseconds? We move from sequential scanning to direct access via indexing.",
                "hook": "Searching without an index is like reading every book in the library to find one quote."
            }
        },
        {
            "slideNumber": 2,
            "type": "standard",
            "title": "Inverted Files (The Index)",
            "content": {
                "definition": "The core data structure of all modern search engines. A mapping from words to the lists of documents they appear in.",
                "text": "Structure: 1. Vocabulary (The words), 2. Postings Lists (The IDs), 3. Payloads (Frequency/Position).",
                "hook": "Word 'Data' -> [Doc 5, Doc 88, Doc 102]"
            }
        },
        {
            "slideNumber": 3,
            "type": "diagram",
            "title": "Visualizing the Inverted Index",
            "content": {
                "description": "Logic of mapping terms to document identifiers.",
                "steps": [
                    "Extract Terms (Vocabulary)",
                    "Sort Terms Alphabetically",
                    "Create Postings Lists (DocIDs)",
                    "Apply Compression (D-Gaps)",
                    "Final Searchable Structure"
                ]
            }
        },
        {
            "slideNumber": 4,
            "type": "standard",
            "title": "Boolean Queries",
            "content": {
                "text": "Searching by combining terms with AND, OR, and NOT. These are solved by merging sorted postings lists.",
                "outcomes": [
                    "AND: Intersection of lists.",
                    "OR: Union of lists.",
                    "NOT: Difference of lists."
                ]
            }
        },
        {
            "slideNumber": 5,
            "type": "standard",
            "title": "Sequential Searching",
            "content": {
                "text": "Scanning the raw text file from start to finish (e.g. grep).",
                "problem": "Too slow for massive data, but necessary for complex pattern matching that isn't indexed.",
                "algorithms": [
                    "KMP (Knuth-Morris-Pratt)",
                    "Boyer-Moore",
                    "Aho-Corasick"
                ]
            }
        },
        {
            "slideNumber": 6,
            "type": "list",
            "title": "Pattern Matching & Structural Queries",
            "items": [
                "Pattern Searching: Using Automata or Suffix Trees to find wildcards (*) in indexed text.",
                "Structural Searching: Using the index to find keywords within specific document segments (like Title or Author).",
                "Proximity Searching: Finding words within 'N' positions of each other."
            ]
        },
        {
            "slideNumber": 7,
            "type": "standard",
            "title": "Index Compression",
            "content": {
                "text": "Making the index fit in RAM. We compress the postings lists using Gap Encoding.",
                "outcomes": [
                    "D-Gaps: Store [100, 105, 110] as [100, 5, 5].",
                    "Bit-level Compression: Variable Byte, Gamma/Delta codes.",
                    "Dictionary Compression: Front coding."
                ]
            },
            "formula": {
                "equation": "g_i = d_{i} - d_{i-1} \\quad \\text{where } d_0 = 0",
                "description": "Delta Gaps (Gap Encoding) reduce the magnitude of numbers in a postings list by storing differences between consecutive document IDs rather than absolute values.",
                "terms": [
                    {
                        "symbol": "d_i",
                        "meaning": "The i-th Document ID in a sorted postings list"
                    },
                    {
                        "symbol": "g_i",
                        "meaning": "The gap (difference) to be stored in the compressed index"
                    },
                    {
                        "symbol": "d_{i-1}",
                        "meaning": "The previous Document ID in the list"
                    }
                ],
                "calculation": {
                    "exampleTitle": "Gap Encoding Transformation",
                    "description": "Compressing a postings list for a common term.",
                    "steps": [
                        {
                            "label": "Sorted List",
                            "formula": "D = [4500, 4503, 4510, 4525]",
                            "note": "Document IDs are large (4 digits)."
                        },
                        {
                            "label": "Calculate First Entry",
                            "formula": "g_1 = 4500 - 0 = 4500",
                            "note": "First entry is stored as is."
                        },
                        {
                            "label": "Calculate Subsequent Gaps",
                            "formula": "g_2=3, g_3=7, g_4=15",
                            "note": "D-Gaps are 4503-4500, 4510-4503, etc."
                        },
                        {
                            "label": "Compressed Sequence",
                            "formula": "G = [4500, 3, 7, 15]",
                            "note": "Smaller numbers require fewer bits to store."
                        }
                    ],
                    "input": "[4500, 4503, 4510, 4525]",
                    "output": "[4500, 3, 7, 15] (Compressed)"
                }
            }
        },
        {
            "slideNumber": 8,
            "type": "activity",
            "title": "Activity: List Merge",
            "content": {
                "activity": "The AND Gate",
                "description": "List 1: [2, 5, 10, 22, 31]. List 2: [5, 12, 22, 45]. What is the result of (List 1 AND List 2)? How many comparisons did you make?"
            }
        },
        {
            "slideNumber": 9,
            "type": "quiz",
            "title": "Topic Quiz",
            "questions": [
                "What are the three parts of an inverted file?",
                "Why is a sorted postings list important for Boolean queries?",
                "When is sequential searching better than indexing?",
                "Explain D-gap compression."
            ]
        },
        {
            "slideNumber": 10,
            "type": "python_demo",
            "title": "Python Demo: Rocchio Formula",
            "content": {
                "code": "def rocchio_update(q_old, rel_docs, non_rel_docs, alpha=1.0, beta=0.75, gamma=0.25):\n    # Simplified: Vector Addition\n    q_new = [alpha * x for x in q_old]\n    \n    # Add relevant influence\n    for doc in rel_docs:\n        q_new = [q + beta * d for q, d in zip(q_new, doc)]\n        \n    # Subtract non-relevant influence\n    for doc in non_rel_docs:\n        q_new = [q - gamma * d for q, d in zip(q_new, doc)]\n        \n    return [round(x, 2) for x in q_new]\n\nq = [1.0, 0.0]\nrel = [[0.8, 0.2]]\nnon = [[0.1, 0.9]]\n\nupdated = rocchio_update(q, rel, non)\nprint(f\"New Query Vector: {updated}\")",
                "input": "Q:[1,0], Rel:[[0.8, 0.2]], Non:[[0.1, 0.9]]",
                "output": "New Query Vector: [1.58, -0.07]",
                "interpretation": "Rocchio moves the query vector closer to relevant docs and away from non-relevant ones.\nThe new vector [1.58, -0.07] has increased its first dimension (where the relevant doc was strong).\nThis is the mathematical basis for 'Relevance Feedback'."
            }
        },
        {
            "slideNumber": 11,
            "type": "summary",
            "title": "Unit Wrap-up",
            "content": {
                "text": "Unit 2 complete. We can now process, query, index, and compress text. Next, we look at the Human Interface.",
                "nextTopic": "Unit 3: User Interfaces",
                "preparation": "Read about HCI (Human-Computer Interaction)."
            }
        }
    ]
}